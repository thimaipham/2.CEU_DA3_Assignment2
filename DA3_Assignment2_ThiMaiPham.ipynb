{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e707983",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4507ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from patsy import dmatrices\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95523fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA IMPORT - FROM GITHUB\n",
    "data_raw = pd.read_csv('https://raw.githubusercontent.com/thimaipham/2.CEU_DA3_Assignment2/main/listings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979336b",
   "metadata": {},
   "source": [
    "### 1. Data Featuring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1564413d",
   "metadata": {},
   "source": [
    "##### Data describe:\n",
    "- The raw dataset comprises 25,480 observations and 76 columns, including some columns that are unnecessary or difficult to use during the modeling process.\n",
    "- Certain important columns are encountering the following issues:\n",
    "    1. The `bedrooms` column has a staggering 99% missing values.\n",
    "    2.The `name` column contains descriptions of apartments, including the number of bedrooms.\n",
    "    3. The `bathrooms` column has no data.\n",
    "The bathroom_text column has data but is currently of object type due to the presence of the word 'bath' in the entries.\n",
    "The price column is currently of object type as it contains the '$' symbol.\n",
    "Several columns exhibit a high percentage of missing values (ranging from 40% to 90%).The raw dataset comprises 25,480 observations and 76 columns, including some columns that are unnecessary or difficult to use during the modeling process.\n",
    "Certain important columns are encountering the following issues:\n",
    "The bedrooms column has a staggering 99% missing values.\n",
    "The name column contains descriptions of apartments, including the number of bedrooms.\n",
    "The bathrooms column has no data.\n",
    "The bathroom_text column has data but is currently of object type due to the presence of the word 'bath' in the entries.\n",
    "The price column is currently of object type as it contains the '$' symbol.\n",
    "Several columns exhibit a high percentage of missing values (ranging from 40% to 90%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23fdec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex looks for a number followed by the word 'bedroom' or 'bedrooms'\n",
    "data_raw['bedroom_extract'] = data_raw['name'].str.extract('(\\d+) bedroom')\n",
    "\n",
    "# Convert the extracted bedroom numbers to numeric type\n",
    "data_raw['bedroom_extract'] = pd.to_numeric(data_raw['bedroom_extract'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "08d6e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary columns to streamline the dataset for this assignment\n",
    "# List of columns to be dropped based on the description and analysis\n",
    "columns_to_drop = [\n",
    "    'id', 'listing_url', 'scrape_id', 'name', 'last_scraped', 'description',\n",
    "    'neighborhood_overview', 'picture_url', 'host_id', 'host_url','bedrooms','host_name', \n",
    "    'host_thumbnail_url', 'host_picture_url', 'host_about', 'host_neighbourhood',\n",
    "    'host_listings_count', 'host_total_listings_count', 'neighbourhood', \n",
    "    'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'calendar_last_scraped', \n",
    "    'license', 'host_location', 'source','first_review','last_review','host_verifications',\n",
    "    'calendar_updated', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', \n",
    "    'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', \n",
    "    'amenities' # amenities column is emty with [] symbol\n",
    "]\n",
    "\n",
    "# Dropping the columns from the DataFrame\n",
    "data_cleaned = data_raw.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# We focus on apartments with 2<= n <= 6\n",
    "data_cleaned = data_cleaned[(data_cleaned.accommodates >= 2) & (data_cleaned.accommodates <= 6)]\n",
    "\n",
    "# Removing rows with null values in the 'price' variable for accurate modeling\n",
    "data_cleaned = data_cleaned.dropna(subset=['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3272b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'bathrooms_text' to a numeric 'bathrooms' column by extracting the number\n",
    "data_cleaned['bathrooms'] = data_cleaned['bathrooms_text'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# Convert 'price' to a numeric column by removing the '$' and ',' then converting to float\n",
    "data_cleaned['price'] = data_cleaned['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Drop the original 'bathrooms_text' column as it's now redundant\n",
    "data_cleaned = data_cleaned.drop('bathrooms_text', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6295b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentage = data_cleaned.isnull().mean() * 100\n",
    "\n",
    "# Due to some columns which have more than 40% of missing values, I will drop those columns\n",
    "# Identify columns with more than 40% missing values\n",
    "columns_to_drop_missing = missing_percentage[missing_percentage > 40].index\n",
    "\n",
    "# Drop these columns\n",
    "data_cleaned = data_cleaned.drop(columns=columns_to_drop_missing)\n",
    "\n",
    "# Drop observations with any missing values\n",
    "data_cleaned = data_cleaned.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81501669",
   "metadata": {},
   "source": [
    "##### After cleaning part the cleaned data includes: \n",
    "- 13773 observations\n",
    "- 38 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e465015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
